{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/duy270101/demo/blob/main/notebooks/Multilingual_ASR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5hvo8QWN-a9"
      },
      "source": [
        "# Installing Whisper\n",
        "\n",
        "The commands below will install the Python packages needed to use Whisper models and evaluate the transcription results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZsJUxc0aRsAf"
      },
      "outputs": [],
      "source": [
        "! pip install git+https://github.com/openai/whisper.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3CqtR2Fi5-vP"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "try:\n",
        "    import tensorflow  # required in Colab to avoid protobuf compatibility issues\n",
        "except ImportError:\n",
        "    pass\n",
        "\n",
        "import torch\n",
        "import pandas as pd\n",
        "import urllib\n",
        "import tarfile\n",
        "import whisper\n",
        "import torchaudio\n",
        "\n",
        "from scipy.io import wavfile\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "\n",
        "pd.options.display.max_rows = 100\n",
        "pd.options.display.max_colwidth = 1000\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IMEkgyagYto"
      },
      "source": [
        "# Loading the Fleurs dataset\n",
        "\n",
        "Select the language of the Fleur dataset to download. Please note that the transcription and translation performance varies widely depending on the language. Appendix D.2 in the paper contains the performance breakdown by language."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "17f9e9404ce04eeabfa6bba236ee8754",
            "7fd86755fb374d56ac931d593716b265",
            "6b8ac84f1495490bbbe8a2142553ca84"
          ]
        },
        "id": "L4lPK5106Of2",
        "outputId": "98717b22-ca73-43dc-f9eb-8588ee36856c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dropdown(description='Language:', index=39, options=(('Select language', None), ('----------', None), ('Afrika…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "17f9e9404ce04eeabfa6bba236ee8754"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import ipywidgets as widgets\n",
        "\n",
        "languages = {\"af_za\": \"Afrikaans\", \"am_et\": \"Amharic\", \"ar_eg\": \"Arabic\", \"as_in\": \"Assamese\", \"az_az\": \"Azerbaijani\", \"be_by\": \"Belarusian\", \"bg_bg\": \"Bulgarian\", \"bn_in\": \"Bengali\", \"bs_ba\": \"Bosnian\", \"ca_es\": \"Catalan\", \"cmn_hans_cn\": \"Chinese\", \"cs_cz\": \"Czech\", \"cy_gb\": \"Welsh\", \"da_dk\": \"Danish\", \"de_de\": \"German\", \"el_gr\": \"Greek\", \"en_us\": \"English\", \"es_419\": \"Spanish\", \"et_ee\": \"Estonian\", \"fa_ir\": \"Persian\", \"fi_fi\": \"Finnish\", \"fil_ph\": \"Tagalog\", \"fr_fr\": \"French\", \"gl_es\": \"Galician\", \"gu_in\": \"Gujarati\", \"ha_ng\": \"Hausa\", \"he_il\": \"Hebrew\", \"hi_in\": \"Hindi\", \"hr_hr\": \"Croatian\", \"hu_hu\": \"Hungarian\", \"hy_am\": \"Armenian\", \"id_id\": \"Indonesian\", \"is_is\": \"Icelandic\", \"it_it\": \"Italian\", \"ja_jp\": \"Japanese\", \"jv_id\": \"Javanese\", \"ka_ge\": \"Georgian\", \"kk_kz\": \"Kazakh\", \"km_kh\": \"Khmer\", \"kn_in\": \"Kannada\", \"ko_kr\": \"Korean\", \"lb_lu\": \"Luxembourgish\", \"ln_cd\": \"Lingala\", \"lo_la\": \"Lao\", \"lt_lt\": \"Lithuanian\", \"lv_lv\": \"Latvian\", \"mi_nz\": \"Maori\", \"mk_mk\": \"Macedonian\", \"ml_in\": \"Malayalam\", \"mn_mn\": \"Mongolian\", \"mr_in\": \"Marathi\", \"ms_my\": \"Malay\", \"mt_mt\": \"Maltese\", \"my_mm\": \"Myanmar\", \"nb_no\": \"Norwegian\", \"ne_np\": \"Nepali\", \"nl_nl\": \"Dutch\", \"oc_fr\": \"Occitan\", \"pa_in\": \"Punjabi\", \"pl_pl\": \"Polish\", \"ps_af\": \"Pashto\", \"pt_br\": \"Portuguese\", \"ro_ro\": \"Romanian\", \"ru_ru\": \"Russian\", \"sd_in\": \"Sindhi\", \"sk_sk\": \"Slovak\", \"sl_si\": \"Slovenian\", \"sn_zw\": \"Shona\", \"so_so\": \"Somali\", \"sr_rs\": \"Serbian\", \"sv_se\": \"Swedish\", \"sw_ke\": \"Swahili\", \"ta_in\": \"Tamil\", \"te_in\": \"Telugu\", \"tg_tj\": \"Tajik\", \"th_th\": \"Thai\", \"tr_tr\": \"Turkish\", \"uk_ua\": \"Ukrainian\", \"ur_pk\": \"Urdu\", \"uz_uz\": \"Uzbek\", \"vi_vn\": \"Vietnamese\", \"yo_ng\": \"Yoruba\"}\n",
        "selection = widgets.Dropdown(\n",
        "    options=[(\"Select language\", None), (\"----------\", None)] + sorted([(f\"{v} ({k})\", k) for k, v in languages.items()]),\n",
        "    value=\"ko_kr\",\n",
        "    description='Language:',\n",
        "    disabled=False,\n",
        ")\n",
        "\n",
        "selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eihI6oK6Of2",
        "outputId": "de0a2344-148b-4da4-b380-385b49ffb4f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected language: Vietnamese (vi_vn)\n"
          ]
        }
      ],
      "source": [
        "lang = selection.value\n",
        "language = languages[lang]\n",
        "\n",
        "assert lang is not None, \"Please select a language\"\n",
        "print(f\"Selected language: {language} ({lang})\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "rzKuHGXZh1gk",
        "outputId": "ee04f021-5c87-48fe-d3d7-55590958cecd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0579d729-d266-4b46-9b84-596c3126822a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0579d729-d266-4b46-9b84-596c3126822a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving cuoc_hop - Copy (mp3cut.net) (1).m4a to cuoc_hop - Copy (mp3cut.net) (1).m4a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "model = whisper.load_model(\"base\")\n",
        "result = model.transcribe(\"cuoc_hop - Copy (mp3cut.net) (1).m4a\", language=\"vi\")\n",
        "print(result[\"text\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "HdsuwW1wh_7M",
        "outputId": "b6e6d998-4f96-4c71-a99b-b1ff589d48ba"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'whisper'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-3983076177>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mwhisper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwhisper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"base\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranscribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuoc_hop - Copy (mp3cut.net) (1).m4a\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"vi\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'whisper'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "625ec2db",
        "outputId": "dc60d79b-c06b-439d-da0a-ef7305c27912"
      },
      "source": [
        "!pip install openai-whisper"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai-whisper\n",
            "  Downloading openai-whisper-20240930.tar.gz (800 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/800.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.5/800.5 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (2.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (4.67.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (10.7.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.9.0)\n",
            "Requirement already satisfied: triton>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (3.2.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2.32.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->openai-whisper)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->openai-whisper) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m105.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803404 sha256=641a1ddbd835604e66a28615496e76eb97feb836475f627786a39f367d04a1ee\n",
            "  Stored in directory: /root/.cache/pip/wheels/2f/f2/ce/6eb23db4091d026238ce76703bd66da60b969d70bcc81d5d3a\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, openai-whisper\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 openai-whisper-20240930\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05d75b74",
        "outputId": "d9edc08d-fd0b-4054-fec0-2910836a8858"
      },
      "source": [
        "import whisper\n",
        "model = whisper.load_model(\"base\")\n",
        "result = model.transcribe(\"cuoc_hop - Copy (mp3cut.net) (1).m4a\", language=\"vi\")\n",
        "print(result[\"text\"])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|████████████████████████████████████████| 139M/139M [00:00<00:00, 177MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Chắc khi vào bằng chi tiết, thì hãy đồng điểm vào bằng chi đau hay mà xây dịch, bằng bằng chi, thì không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là b bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là b bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, không phải là bằng chi, đặc biệt từ tan b Cái gì không hỏi, thì sẽ được gần giải. Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái gì? Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng. Cái lớp người dùng.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "model = whisper.load_model(\"large\")\n",
        "result = model.transcribe(\"cuoc_hop - Copy (mp3cut.net) (1).m4a\", language=\"vi\")\n",
        "print(result[\"text\"])"
      ],
      "metadata": {
        "id": "VgnHuLobjQgg",
        "outputId": "3b54eb23-d069-4de7-b6e1-0962863fc3be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████████████████████████████████| 2.88G/2.88G [00:30<00:00, 101MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Năm 2020 đầu biến sau nhất là xây dựng và bảo trị tất cả dữ liệu sổ hóa tập trung, tỏa mặt truy vết. Nhóm đầu biến lớn thứ 2 đó là liên quan về khảo sát, kiên trạng và hạ tầng công nghệ công ty của công ty về cả tấn cứng phần mềm và những tất cả dữ liệu. Nhóm đầu biến thứ 3 đó là xây dựng và ghi công nghiệm về tư vấn đánh giá mức độ truyền thống số như là xây dựng tất cả số của PVSD. Nhóm đầu biến thứ 4 đó là đánh giá so sánh các tấn áp phần mềm truyền thống số để làm cơ sở để làm việc cố lắng, đó là về xây dựng và ghi công nghiệm về phần phòng số thay thế mét. Bảo coi thì trong rất nhiều điều kiện chi tiết thì em cũng tổng hợp là liên quan 5 người nhóm đầu biến trực tiếp này. Thì xuất phát từ cái chỉ đạo lưu nhất là đây là cái tầng thông báo 32 của thông báo Viettelmark trong cuộc họp kết luận của giám đốc với tổng công nghệ an tin truyền thống số trong tháng 12-24. Vậy là em xin đặt kép trong cái phần. Trước khi vào phần chi tiết thì em cũng bảo anh thì hãy đồng biệt nhóm đầu biến số 1 về chỉ đạo anh xây dựng bác bảo trị cơ sở dữ liệu sở hóa đặc trung bảo mật. Thì phòng thông an toàn cũng đó là công văn thực hiện theo cái kế hoạch đã được hình dựng tại công bản số 20 của phòng thông an toàn. Thì nó cũng liên quan đến những 3 cái đồng biến lớn. Em cũng liên quan đến số đồng biến 191. Thì ở đây thì có 3 cái hạng đồng đường. Đồng biến thực hiện đó là về quản lý thiết bị phương án thông tin. Thứ 2 là quản lý dữ liệu. Thứ 3 là quản lý trang đổi thông tin. Thì ở đây cũng có các cái đồng biến chính. Thì em có bảo anh là thực hiện cái việc quản lý này thì sẽ thực hiện trên 5 nguyên tắc quản lý. Về quản lý tập trung, quản lý truy vết, quản lý tập trung, quản lý an toàn bảo mật, quản lý nguyên tắc thông tin. Trong nguyên tắc thứ 5 đó là nguyên tắc hiệu quả. Thì với những cái đồng biến thiết liệu này thì em bảo anh thì. Trong cái phần kết quả thực hiện với nhóm quản lý thiết bị công nghệ thông tin thì về thiết lập DC. Thì trong cái trạng hạ tầng công ty đã có thì quản lý thiết lập lại cho đồng biến quản trung theo nguyên tắc công nghệ hội nhật. Thứ 2 liên quan đến nhóm quản lý thiết bị công nghệ thông tin. Thì ở đây thì về cái nhóm doi của bên cho người dùng cuối thì quản lý là hoàn thành được 67 trên 264 máy. Tập số máy của công ty. Đang gọi là máy của đang văn phòng làm việc của công ty. Thì ở đây thì em cũng về cái phân tích nguyên nhân của em trước cũng có phân tích nguyên nhân. Có phương trình là các đồng minh công văn của em đang có hành liên lại theo phần đồng minh của chị Đặng. Về các phân tích nguyên nhân về tại sao do đồng minh chưa hoàn thành. Thì cái nát trong cái phần giải trí chi tiết hơn về cái phần là quản lý thiết bị thì em sẽ báo vào do đồng minh. Về cái nhóm thứ 3 trong cái quản lý thiết bị công ty đó là kết lập cái group policy. Tức là các cái quy tắc quản lý khi mà những máy đã được kết lối của máy chính người dùng doanh nhân đã kết lối về đồng minh hoàn trọng. Thì được kết lập theo những cái mà admin, ngã chống, quy tắc của em đã kết lập sẵn rồi. Và khi cái máy của người dùng được kết lối về đồng minh thì cũng sẽ add những cái policy đó. Thế tại báo vào anh thì những cái policy thời gian đầu em làm trong công văn số 29 thì cũng là những cái policy đôi bát. Còn chi tiết hơn thì sau những cái công văn mà em đổ xuất lại trong cái domain này báo vào em thì em sẽ có những cái policy chi tiết hơn để áp dụng. Đó là phần là việc lớn nhất của em trong phần này. Thì báo vào anh thì có thể... Trước mình... Anh nghĩ là tương đương mình đi đến đâu mình trao đổi đến đấy để cho nó đỡ rất là mix đầu với các công ty. Trước này em có nói là cái việc xây dựng, cái việc khoản thiết của công ty này, cái việc khoản dữ liệu của công ty, tất cả những cái này thì ở trên công ty đưa ra yêu cầu. Và tổ của Hồng Kinh Thuận Toàn, bây giờ chủ phòng lực lượng tại Hồng Kinh Thuận Toàn xét sẽ tìm kiếm, đánh giá và đề xuất những giải pháp lựa chọn để thực hiện. Thế thì cái này thường thường là mình chỉ làm những đề xuất. Vậy là anh có làm việc, anh có nói là cái chuyện là mình phải tương đương cùng một mục đích như thế có bao nhiêu giải pháp. Rồi anh bạn phải đánh giá các giải pháp, cái nào mình lưu về nào, ưu nhiệt điểm của cái và đề xuất thế nào nó phù hợp, nó phù hợp với tích dụng của công ty. Rồi thì cái này là mình chưa thực hiện được, em quay lại câu chuyện join all bên này. Đánh join all bên thì bọn anh chị, tức là bọn em... Chúng tôi tắt một cuộc báo cáo ấy. Khi báo cáo tức nào thì cái lượng thông tin này sẽ tăng lên. Khi báo cáo tức nào thì cái lượng thông tin này sẽ tăng lên. Em phải cung cấp để cấp đến người ta hiểu được. Ví dụ như thế này, tức là những cái báo cáo của bọn em là chuyên môn. Nhưng mà không phải ai biết được join all bên là cái gì, bọn em phải định nghĩa. Bọn em phải phân tích ra nó... Thứ nhất là cái cấu trúc nó như thế nào, thứ hai là ưu nhiệt điểm của nó là cái gì. Thứ ba là cái điểm yếu, trí tử của nó là cái gì. Toàn bộ các giải pháp bọn em trình bày ở đây thì đều tránh trên nền internet. Nó phù hợp với cái xu hướng IoT thôi. Nhưng mà nó có phù hợp với điều kiện an tâm của công ty của mình ấy không? Nó phù hợp với điều kiện làm việc của, di chuyển của anh chị em mình ấy không? Ví dụ như do bên mà sách máy laptop này đi xuống site của bạn thì nó có truy cập vào cái thơ sở dữ liệu của công ty của anh ta chung với anh ấy không? Câu hỏi này rất là dài. Thế thì, qua lại câu chuyện, toàn bộ những cái này này. Mỗi ngày cạnh xây dựng này, mỗi ngày có nói cái bao nhiêu. Mỗi ngày có nói là nếu mà em xây dựng toàn bộ cái phần mà trên yêu cầu của công ty đã được đưa ra thì có bao nhiêu giải pháp này. Mỗi giải pháp như thuyền như nào mà mình lấy xuất cái giải pháp cụ thể, tăng cứ trên cái tỉnh, quốc tế. Nó phù hợp với cái nhu cầu, cái khả năng đáp ứng của công ty. Nên nguồn lực mình cũng phải có hạng. Đấy, tiếp theo đó là nó phải có cái kiến trúc mở để sau này nâng cấp, mình upgrade, mình tích hợp với các cái mô hữu khác. Nó dễ dàng. Tránh câu chuyện là mình làm gì làm như cái bét bây giờ là một mình không một cái. Rất là khó. Em cũng báo cáo một cái phần mà mình vừa gợi ý nhé. Trong cái slide đưa đường này, trong cái công văn mà đang chuẩn bị chỉnh đáy đó. Cái công văn mà do lội dung của em, cái lội dung đưa đường trong slide này là cái nằm trên công văn. Em chưa lên cái công văn mà mình đã chỉnh đáy. Mỗi em cũng có, mỗi em em cũng chuẩn bị đảm dung. Nhưng mà lội dung mới đưa vào slide này là không. Nhưng mà cái của em đã chuẩn bị lại. Cái câu hỏi của mình, mình không có trả lại em. Báo cáo anh thì cái phần mà doi báo mê đó, thì cũng trong cái giao đoạn trở lại. Em cũng báo cáo anh luôn là trong cái phần thực hiện về hạ tầng doi báo mê thì nó là cái bước, em nghĩ là bước cơ bản nhất để mà kết nối của máy tính người dùng về hạ tầng, về hệ thống. Mà nó cũng không có gì là mới, mà bởi vì bản thân hệ thống của mình đã có sẵn. Chẳng ra do mình đang để mà không sử dụng nó. Chưa giúp ngưng dạng. Thì nó rất đơn giản so với cái giải pháp đó là virtual desktop, virtual tức là cái mà tầng máy tính ảo của một PC ấy, không có ổn cứng. Thì hiện tại thì đơn vị nào đã dùng em ấy gần nhất là tổng tiên đã có bình thường về cái domain rồi. Thì về cái phần vướng thì em báo anh là trong cái thực hiện của hiện tại thì nếu về mặt kỹ thuật thì nó vướng ở những 3 thứ sau. Thứ nhất là về lớp người dùng, lớp thiết bị người dùng là tính là máy tính gắn mộ nhân viên. Thì nó có phần vướng đó là chưa được cài đặt cái Windows Pro. Nó là điều mình cần để mà active về cái domain control. Thì do trước đây chính sách của mình đang là mua máy tính OM thì nó cài sẵn Windows Home ấy. Thì giá đúng theo yêu cầu của văn phòng của mình. Sau đó thì công ty mình cũng đã mua thử nghiệm 1 lần 50Ki Windows Pro. Lần văn phòng mình mua cho năm ngoái ấy thì cũng đã trang bị rồi. Thì những cái máy đã được trang bị 50Ki mà em vừa active xong rồi. Thì cũng đã thử nghiệm xong. Và em cũng giả soát là theo quy định mua sắm thiết bị văn phòng của công ty mình từ năm 2021 theo quy định số 2 trên 8. 2 trên 8 thì... Trong quy định của công ty mình là điều số 12 và điều số 15. Em sẽ đưa khoảng 12 khoảng 15. Thì cũng đã quy định về kinh chức mà mua sắm là phải active được domain control. Tức là đã có quy định của công ty rồi. Mà em cũng chưa tìm hiểu rõ là tại sao mình có mua những cái để đặt vào yêu cầu đó từ năm 2021 là cái cơ sở. Thì trong cái công văn mà do đồng minh sau khi em trả về em cũng đã phân tích lại và mình đã biết là về mặt cơ sở là phòng không đưa vào cơ sở nào mới. Không đưa vào cơ sở mới mà quy định đó là ở trong quy định của công ty có rồi. Thì em cũng trong cái đề xuất sau công văn này. Em để lại là các cái xí nghiệm mà không được qua phòng không đưa vào cơ sở mua thì phải tôn thủ nghiên tục ngay với công ty để mua sắm thiết bị văn phẩm. Đáp ứng ý của domain control. Tránh là mua thiết bị với lớp người dùng lại không đạt mà sau đó lại đi xử lý cho nên mua lại thì nó thiếu đồng bộ. Đấy là về mặt của lớp người dùng. Bọn em xuống hãy tắt cái ví dụ này cho bọn em. Em cũng giải thích lại suy nghĩ này xong sau em lại quay lại tiếp về cái phần hạ tầng của em mình nhé. Thì bọn em... Như anh có góp ý của em thì em cũng có thất tích lại lên những cái thuật lữ về công nghệ. Thì domain control thì là một cái máy chủ trong cái mạng sử dụng của Microsoft Server. Tức là nó dùng cho cái hỗ trợ giao thị quản trị của doanh nghiệp trong quản lý thiết bị người dùng. Và cái này thì nó đã có từ Windows Server 2000 rồi. Em tìm hiểu theo tài liệu Microsoft. Tuy nhiên những cái tính năng của nó mà hỗ trợ nhất về quản trị từ xa tức là không phải mạng local đối bộ á. Mà có thể hỗ trợ về Internet hoặc là đường Metro One ở đường xa. Thì là đối với Windows Server 2016 là chính là cái bản mà mình đang dùng. Thì là hỗ trợ những cái tính năng theo nhu cầu của Microsoft. Vậy đấy là domain control. Thứ hai là cái vai trò của domain control thì ai cũng nói rồi. Thì nó có 3 cái vai trò chi tiết hơn. Thì ở đây có cái tính đó là tính là xác thực và thân quyền. Xác thực ở đây là chạy những cái máy tính mà không có mang cái ID, cái địa chỉ em tặng gọi là ID công ty á. Mà từ bên ngoài thì sẽ không vào được cái máy server công ty. Và những cái mà thuộc mà đã được công ty quản lý, quản lý server. Đấy là lớp bảo vệ cho mình. Dạ. Thứ hai thì em biết công an này sau khi lên file có một cái giải thích rất nhiều thông tin mà mọi người trong các mục tiêu vừa qua. Và có anh là cũng mọi người có một cái chuyện nhầm nhầm. Ở đó một nhân viên là hiểu rằng mình hãy tiếp mấy domain control này. Và cái kiểm soát, lộ bộ dữ liệu tức là mình lấy gì đó máy trong máy của người này, của anh ấy, của anh Bảo ấy, của người đa. Mà mọi người không hiểu đây là cái quản lý tập trung vào dữ liệu của mình. Và mọi người đang tăng cái lớp bảo vệ của mình với bên ngoài. Thì đây là vai trò của nó. Nhưng mà em sau đi thực tế á. Thì cũng có những cái nội công ty không hiểu là người ta hiểu là đồ hãy ti công ty đang lấy cái gì dữ liệu trong máy của các mọi người. Khi máy tiếp vào đây. Thì đây thì nó sẽ xác cho dân quyền và lấy bảo vệ bản thân của hệ thống. Và thứ hai là cũng trong cái tính bảo vệ là group policy. Tức là thay vì cái người mà admin công ty đi cài đặt từng cái phân quyền permission trên từng máy tính. Thì khi đã kết nối với đây thì sẽ sử dụng cái group policy. Tức là group policy là khi máy em đã kết nối về. Là em sẽ mặc định không được cảm nhận được. Em sẽ mặc định không được cảm nhận được bên ngoài vào nữa. Thì vậy là nó sẽ khóa từ xa luôn. Cái này thì nó tính năng là hoàn toàn trong video server có sẵn. Mà do thế thì cũng tính năng hoàn toàn trong cái này thì hoàn toàn khi mà dùng video server. Và tố hình trong này thì admin công ty phải làm được đấy. Không cần phải yêu cầu lưu tập hay là mua xong đi bên ngoài. Thứ ba cái tính năng, cái ý nghĩa quan trọng của domain control là phải tập trung vào những quả. Cho khách, những quả chỉ viên có thể thiết lập từ xa. Những cái tố hình và ủng hộ cho người dùng. Cũng như là có thể trong tương lai là những cái quản quyền. Cái quản quyền mình mua bên ngoài. Ví dụ như là em ví dụ một cái phần mềm AutoCAD đi. AutoCAD mà mình theo cái license mà giảm như license personal. Là cài một máy, một máy thuộc cái máy người ta. Nhưng mà khi kích hoạt license theo dạng server. Thì nó cất cái gói là cứ biết là A bằng 4 mên của VGKD là kích hoạt. Chứ nó không phải thuộc là em chung ngay tài khoản gì đó. Thì đấy là một cái tính năng sử dụng cho cái phần mềm kích hoạt doanh nghiệp. Về AutoCAD em không nhớ rõ đúng chưa. Nhưng mà một số phần mềm nó có như vậy. Ví dụ như trên tổng công ty trước em là một số phần mềm, những 2 xít này. Thì là tổng team mua, mua chung cho các đơn vị dùng. Thì khi kích hoạt A bằng VGKD cho nó đi thì là từ xa sử dụng và kết nối với server công ty. Và cái này nó rất quan trọng là mình quản lý tài nguyên. Tránh cái máy của một cá nhân mà cài cái bảo quyền như thế này. Sau đó em nghỉ việc còn bạn nghỉ việc thì máy nó hết tích thì nó mang đi. Nhưng mà em thu hồi lại thì nó là tài sản của công ty, tài nguyên của công ty chứ không thuộc về ai cả. Nhưng mà nếu mà cài thế này thì những cái ổ cứng vật lý của cái PC còn không? Em bảo anh, nếu mà những cái phần mềm thứ 3 thì vẫn phải cần cài trên laptop. Laptop chắc chắn là sẽ bị em ổ cứng rồi. Cái PC này có không? Dạ, theo em được biết những cái phần mềm thứ 3 là vẫn phải cài trên PC của họ. Còn những cái phần mềm cho RAMI em cập nhật thì em cũng chưa được cập nhật. Nhưng những cái phần mềm trước đây em được biết là phần mềm kỹ thuật là vẫn phải cài một cái bảng. Ví dụ như là không phải cài bảng full 1GB. Nó phải 800MB, khoảng phần và lại nó sẽ kết nối dữ liệu về cái nó trên server của công ty thì nó sẽ xác nhận ra đó. Do em chỉ có trải nghiệm những cái phần mềm như trước ngày ấy. Như là AutoCAD, à không, em xin lỗi, iSEED thì em đang thấy hình thức đó. Và trên tổng ty cũng trước em cũng thấy được nào. Ví dụ như AutoCAD, iSEED có cái gốc sử nó chạy trên Virtual PC không? Virtual PC thì em chưa tìm hiểu. Trước đây thì em đã tìm hiểu với bạn gần nhất một cái nhu cầu mình gần cần đó là Mất card nhưng mà vẫn phải có lịch hệ thống nội mạng xét tích lên. Thì cái phần của xét tích hệ thống nội mạng xét tích được theo server. Và còn những cái phần mềm đơn giản em cũng chưa tìm hiểu được. Chị đã xem hiện tại nó có trợ như vậy chưa? Tức là cái nhu cầu đầu tiên đưa ra là Cái quả bù của dữ liệu xảy ra trong quá trình là việc Em nghĩ nó phải có những tập trung. Chứ nó không được lưu trữ tập đoán trên PC. Nếu như cái này thì nó chỉ được cái là em có thể dùng các phần mềm đồng chung Và em lưu trữ tập trung ở trên quả lý tập trung. Tức là em lưu trữ, em quản lý tập trung lưu trữ ở cấp độ đầu ti. Cấp độ lưu trữ nó không quản lý được. Dạ, dạ, hiểu rồi. Nó chỉ có cái thôi. Dữ liệu trong quá trình mà người dùng người đã thao tác trên PC thì nó vẫn phải lưu trữ trên PC. Nó có thể sao một bản trên cái server chụp của nó em. Nhưng quan trọng nhất là mình chiếm tiêu cái lưu trữ trên PC. Vì cái lưu trữ trên PC người ta cũng copy cả. Mặc dù mình có thể truy viết được nhưng cái đấy đã xảy ra rồi. Dạ. Dạ. Ủa, anh em có biết những cái dạng phần mềm, hệ thống dạng như phần mềm B3 mà đã sử dụng hoàn toàn trên server? Cũng đi trên thức nào không cần cài đặt gì trên cái bảng phụ trên máy tính cá nhân á. Bánh tính PC á. Anh em chứ không nhận. Còn cái hình thức server thì anh em nhận thức gì rồi? Thực ra rất nhiều phần mềm có cái trách sử. Tức là có bảng web. À. Đấy, anh em không biết là cái auto-cast có bảng web hay không. có bản web hay không. Rất nhiều người có bản web, mà bản web chỉ đứng chữ trên server thôi, nó không đốt xuống PC.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from google.colab import files\n",
        "\n",
        "# Lấy kết quả từ Whisper\n",
        "raw_text = result[\"text\"]\n",
        "\n",
        "# Dùng regex để tách câu dựa trên dấu kết thúc câu\n",
        "sentences = re.split(r'(?<=[.!?])\\s+', raw_text.strip())\n",
        "\n",
        "# Gộp lại thành đoạn văn với mỗi câu là một dòng\n",
        "formatted_text = \"\\n\".join(sentences)\n",
        "\n",
        "# Lưu ra file txt\n",
        "output_filename = \"ket_qua_chuyen_am_dep.txt\"\n",
        "with open(output_filename, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(formatted_text)\n",
        "\n",
        "# Tải về máy\n",
        "files.download(output_filename)"
      ],
      "metadata": {
        "id": "CU9dquMTmQFo",
        "outputId": "17509d08-455a-47cd-8144-1b18d22deef1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9a74b6d3-8d2d-4853-a46c-39feb0f0300d\", \"ket_qua_chuyen_am_dep.txt\", 20299)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"ket_qua_chuyen_am.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(result[\"text\"])\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"ket_qua_chuyen_am.txt\")"
      ],
      "metadata": {
        "id": "xJ5vKuOVl78O",
        "outputId": "4105c050-2531-4d04-c0ec-fea3841d94f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_931361a9-4be4-47e4-8cd2-089964251a7e\", \"ket_qua_chuyen_am.txt\", 20300)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "17f9e9404ce04eeabfa6bba236ee8754": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "Select language",
              "----------",
              "Afrikaans (af_za)",
              "Amharic (am_et)",
              "Arabic (ar_eg)",
              "Armenian (hy_am)",
              "Assamese (as_in)",
              "Azerbaijani (az_az)",
              "Belarusian (be_by)",
              "Bengali (bn_in)",
              "Bosnian (bs_ba)",
              "Bulgarian (bg_bg)",
              "Catalan (ca_es)",
              "Chinese (cmn_hans_cn)",
              "Croatian (hr_hr)",
              "Czech (cs_cz)",
              "Danish (da_dk)",
              "Dutch (nl_nl)",
              "English (en_us)",
              "Estonian (et_ee)",
              "Finnish (fi_fi)",
              "French (fr_fr)",
              "Galician (gl_es)",
              "Georgian (ka_ge)",
              "German (de_de)",
              "Greek (el_gr)",
              "Gujarati (gu_in)",
              "Hausa (ha_ng)",
              "Hebrew (he_il)",
              "Hindi (hi_in)",
              "Hungarian (hu_hu)",
              "Icelandic (is_is)",
              "Indonesian (id_id)",
              "Italian (it_it)",
              "Japanese (ja_jp)",
              "Javanese (jv_id)",
              "Kannada (kn_in)",
              "Kazakh (kk_kz)",
              "Khmer (km_kh)",
              "Korean (ko_kr)",
              "Lao (lo_la)",
              "Latvian (lv_lv)",
              "Lingala (ln_cd)",
              "Lithuanian (lt_lt)",
              "Luxembourgish (lb_lu)",
              "Macedonian (mk_mk)",
              "Malay (ms_my)",
              "Malayalam (ml_in)",
              "Maltese (mt_mt)",
              "Maori (mi_nz)",
              "Marathi (mr_in)",
              "Mongolian (mn_mn)",
              "Myanmar (my_mm)",
              "Nepali (ne_np)",
              "Norwegian (nb_no)",
              "Occitan (oc_fr)",
              "Pashto (ps_af)",
              "Persian (fa_ir)",
              "Polish (pl_pl)",
              "Portuguese (pt_br)",
              "Punjabi (pa_in)",
              "Romanian (ro_ro)",
              "Russian (ru_ru)",
              "Serbian (sr_rs)",
              "Shona (sn_zw)",
              "Sindhi (sd_in)",
              "Slovak (sk_sk)",
              "Slovenian (sl_si)",
              "Somali (so_so)",
              "Spanish (es_419)",
              "Swahili (sw_ke)",
              "Swedish (sv_se)",
              "Tagalog (fil_ph)",
              "Tajik (tg_tj)",
              "Tamil (ta_in)",
              "Telugu (te_in)",
              "Thai (th_th)",
              "Turkish (tr_tr)",
              "Ukrainian (uk_ua)",
              "Urdu (ur_pk)",
              "Uzbek (uz_uz)",
              "Vietnamese (vi_vn)",
              "Welsh (cy_gb)",
              "Yoruba (yo_ng)"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "Language:",
            "description_tooltip": null,
            "disabled": false,
            "index": 81,
            "layout": "IPY_MODEL_7fd86755fb374d56ac931d593716b265",
            "style": "IPY_MODEL_6b8ac84f1495490bbbe8a2142553ca84"
          }
        },
        "7fd86755fb374d56ac931d593716b265": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b8ac84f1495490bbbe8a2142553ca84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}